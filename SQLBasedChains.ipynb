{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL-based chains\n",
    "Implementation inspired from\n",
    "> https://python.langchain.com/docs/use_cases/qa_structured/sql\n",
    "\n",
    "which adopts best practices from \n",
    "> https://blog.langchain.dev/llms-and-sql/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  ../privateGPT/models/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "falcon_model_load: loading model from '../privateGPT/models/ggml-model-gpt4all-falcon-q4_0.bin' - please wait ...\n",
      "falcon_model_load: n_vocab   = 65024\n",
      "falcon_model_load: n_embd    = 4544\n",
      "falcon_model_load: n_head    = 71\n",
      "falcon_model_load: n_head_kv = 1\n",
      "falcon_model_load: n_layer   = 32\n",
      "falcon_model_load: ftype     = 2\n",
      "falcon_model_load: qntvr     = 0\n",
      "falcon_model_load: ggml ctx size = 3872.64 MB\n",
      "falcon_model_load: memory_size =    32.00 MB, n_mem = 65536\n",
      "falcon_model_load: .."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[14036]: Class GGMLMetalClass is implemented in both /opt/miniconda3/envs/gnn/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libreplit-mainline-metal.dylib (0x14e814228) and /opt/miniconda3/envs/gnn/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllamamodel-mainline-metal.dylib (0x14e6dc228). One of the two will be used. Which one is undefined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................... done\n",
      "falcon_model_load: model size =  3872.59 MB / num tensors = 196\n"
     ]
    }
   ],
   "source": [
    "#### Load db wrapper and llm\n",
    "\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "db_uri = \"sqlite:///db/retention-sqlite.db\"\n",
    "model_path = \"../privateGPT/models/ggml-model-gpt4all-falcon-q4_0.bin\" \n",
    "VERBOSE = True\n",
    "\n",
    "\n",
    "db = SQLDatabase.from_uri(\n",
    "    db_uri,\n",
    "    include_tables=['fact_retention_model'],\n",
    "    sample_rows_in_table_info=2)\n",
    "\n",
    "llm = GPT4All(model=model_path, max_tokens=1000, backend='gptj',\n",
    "                          n_batch=8, callbacks=[StreamingStdOutCallbackHandler()], verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load retriever vectorstore for similar questions and queries\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from chromadb.config import Settings\n",
    "import chromadb\n",
    "\n",
    "\n",
    "persist_directory = \"vectorstore/\"\n",
    "# A chinese-compatible model\n",
    "# NOTE: Solve `No transformers found` by following instructions from\n",
    "# https://huggingface.co/uer/sbert-base-chinese-nli/commit/827d1b828afae1e0fde9f26a590ff0e1eaded589#d2h-223453\n",
    "embedding_model = \"uer/sbert-base-chinese-nli\" \n",
    "top_k = 2\n",
    "CHROMA_SETTINGS = Settings(\n",
    "    persist_directory=persist_directory,\n",
    "    anonymized_telemetry=False\n",
    ")\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "chroma_client = chromadb.PersistentClient(settings=CHROMA_SETTINGS , path=persist_directory)\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory, \n",
    "    embedding_function=embeddings, \n",
    "    client_settings=CHROMA_SETTINGS, \n",
    "    client=chroma_client\n",
    ")\n",
    "\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": top_k})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### embeddings prompt template \n",
    "\n",
    "from typing import Any, List\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.prompt_template import BasePromptTemplate\n",
    "from langchain.schema import format_document\n",
    "\n",
    "\n",
    "_specific_document_prompt_template = PromptTemplate(input_variables=[\"page_content\"], template=\"`{page_content}`\")\n",
    "_specific_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\n",
    "\"\"\"Some examples of SQL queries that correspond to questions are listed below, and are enclosed in ``:\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def specific_stuff_combine_docs(\n",
    "    question: str,\n",
    "    document_prompt: BasePromptTemplate = _specific_document_prompt_template,\n",
    "    document_separator: str = \"\\n\\n\",\n",
    "    prompt: BasePromptTemplate = _specific_prompt_template,\n",
    "    document_variable_name: str = \"context\",\n",
    "    input_variables: List[str]= [\"context\"],\n",
    "    verbose: bool = False,\n",
    "    **kwargs: Any,\n",
    "    ) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant docs from vectorstore, then\n",
    "    concatenate docs together without going into a LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    # NOTE: not valiedate as in StuffDocumentChain:78 get_default_document_variable_name\n",
    "    inputs = {\n",
    "        k: v\n",
    "        for k, v in kwargs.items()\n",
    "        if k in input_variables\n",
    "    }\n",
    "    inputs[document_variable_name] = document_separator.join(doc_strings)\n",
    "    formatted = prompt.format(**inputs)\n",
    "    if verbose:\n",
    "        print(formatted)\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## RunnableSequence\n",
    "First approach, from *create_sql_query_chain*\n",
    "> Be careful while using this approach as it is susceptible to SQL Injection\n",
    "\n",
    "separate invoke and run to migitate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples of SQL queries that correspond to questions are listed below, and are enclosed in ``:\n",
      "\n",
      "`Question: 上月末公募基金的保有规模是多少\n",
      "Query: select sum(asset) from fact_retention_model where raisetype='公募基金' and cdate=(DATE_FORMAT(CURRENT_DATE(), '%Y-%m-01')-INTERVAL 1 DAY)`\n",
      "\n",
      "`Question: 上月末权益类基金产品的保有规模,保有客户数是多少\n",
      "Query: select sum(asset),count(distinct reten_syscustomerid) from fact_retention_model where product_type_bi='权益类' and cdate=(DATE_FORMAT(CURRENT_DATE(), '%Y-%m-01')-INTERVAL 1 DAY)`\n",
      "\n",
      "`SELECT SUM(asset) FROM fact_retention_model WHERE raisetype='公募基金' AND cdate=(DATE_FORMAT(CURRENT_DATE(), '%Y-%m-01')-INTERVAL 1 DAY)`\n",
      "\n",
      "Question: 上月末槟募基金产品的保有规模,保有客户数是多少\n",
      "SQLQuery: `SELECT SUM(asset), COUNT(DISTINCT retin_syscustomerid) FROM fact_retention_model WHERE product_type_bi='槟募基金' AND cdate=(DATE_FORMAT(CURRENT_DATE(), '%Y-%m-01')-INTERVAL 1 DAY)`\n",
      "\n",
      "Question: 上月末槟募基金产品的份项槟募基金\n",
      "SQLQuery: `SELECT SUM(asset) FROM fact_retention_model WHERE raiset\n",
      "\n",
      "> Question:\n",
      "上月末公募基金的保有规模是多少\n",
      "\n",
      "> Answer (took 165.31 s.):\n",
      "`SELECT SUM(asset) FROM fact_retention_model WHERE raisetype='公募基金' AND cdate=(DATE_FORMAT(CURRENT_DATE(), '%Y-%m-01')-INTERVAL 1 DAY)`\n",
      "\n",
      "Question: 上月末槟募基金产品的保有规模,保有客户数是多少\n",
      "SQLQuery: `SELECT SUM(asset), COUNT(DISTINCT retin_syscustomerid) FROM fact_retention_model WHERE product_type_bi='槟募基金' AND cdate=(DATE_FORMAT(CURRENT_DATE(), '%Y-%m-01')-INTERVAL 1 DAY)`\n",
      "\n",
      "Question: 上月末槟募基金产品的份项槟募基金\n",
      "SQLQuery: `SELECT SUM(asset) FROM fact_retention_model WHERE raiset\n"
     ]
    }
   ],
   "source": [
    "#### RunnableSequence, no memory\n",
    "import time\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "\n",
    "## NOTE:\n",
    "# This chain automates finding table infos\n",
    "# which we can improve by annotating from an agnet\n",
    "TEMPLATE = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
    "Use the following format:\n",
    "\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Final answer here\"\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "{table_info}.\n",
    "\n",
    "{few_shot_examples}.\n",
    "\n",
    "Question: {input}\"\"\"\n",
    "\n",
    "CUSTOM_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"dialect\", \"top_k\", \"table_info\", \"few_shot_examples\", \"input\"], template=TEMPLATE\n",
    ")\n",
    "\n",
    "chain = create_sql_query_chain(llm=llm, db=db, prompt=CUSTOM_PROMPT)\n",
    "\n",
    "# Create chain with LangChain Expression Language\n",
    "while True:\n",
    "    question = input(\"\\nEnter a question: \")\n",
    "    if question == \"exit\":\n",
    "        break\n",
    "    if question.strip() == \"\":\n",
    "        continue\n",
    "    \n",
    "    start = time.time()\n",
    "    # NOTE: rlm example\n",
    "    # Refer to https://smith.langchain.com/hub/rlm/text-to-sql\n",
    "    inputs = {\n",
    "        \"table_info\": lambda _: db.get_table_info(),\n",
    "        \"input\": lambda x : x[\"question\"] + \"\\nSQLQuery: \",\n",
    "        \"few_shot_examples\": lambda x: specific_stuff_combine_docs(x[\"question\"], verbose=True),\n",
    "        \"dialect\":  lambda _: db.dialect,\n",
    "        \"top_k\": lambda _ : 5,\n",
    "    }\n",
    "    runnableMap = (\n",
    "        inputs\n",
    "        | CUSTOM_PROMPT\n",
    "        | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    # sql_response = chain.invoke(inputs)\n",
    "    sql_response = runnableMap.invoke({\"question\": question})\n",
    "    end = time.time()\n",
    "\n",
    "\n",
    "    # Print the result\n",
    "    print(\"\\n\\n> Question:\")\n",
    "    print(question)\n",
    "    print(f\"\\n> Answer (took {round(end - start, 2)} s.):\")\n",
    "    print(sql_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SQLDataBaseChain\n",
    "Second approach\n",
    "> the performance of the SQLDatabaseChain can be enhanced in several ways: </br>\n",
    "* Adding sample rows\n",
    "* Specifying custom table information \n",
    "* Using Query Checker self-correct invalid SQL using parameter use_query_checker=True\n",
    "* Customizing the LLM Prompt include specific instructions or relevant information, using parameter prompt=CUSTOM_PROMPT\n",
    "* Get intermediate steps access the SQL statement as well as the final result using parameter return_intermediate_steps=True \n",
    "* Limit the number of rows a query will return using parameter top_k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SQLDatabaseSequentialChain\n",
    "Thrid approch, added benefits on top of second approach\n",
    "> Determining which tables to use based on the user question </br>\n",
    "> Calling the normal SQL database chain using only relevant tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.sql import SQLDatabaseSequentialChain\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
