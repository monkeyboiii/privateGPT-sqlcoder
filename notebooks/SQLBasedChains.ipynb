{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL-based chains\n",
    "Implementation inspired from:\n",
    "> https://python.langchain.com/docs/use_cases/qa_structured/sql\n",
    "\n",
    "which adopts best practices from:\n",
    "> https://blog.langchain.dev/llms-and-sql/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load retriever vectorstore for similar questions and queries\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from chromadb.config import Settings\n",
    "import chromadb\n",
    "\n",
    "\n",
    "# A chinese-compatible embedding model\n",
    "# NOTE: Solve `No transformers found` by following instructions from\n",
    "# https://huggingface.co/uer/sbert-base-chinese-nli/commit/827d1b828afae1e0fde9f26a590ff0e1eaded589#d2h-223453\n",
    "embedding_model = \"uer/sbert-base-chinese-nli\" \n",
    "persist_directory = \"../vectorstore/\"\n",
    "score_threshold = 0.8\n",
    "top_k = 3\n",
    "CHROMA_SETTINGS = Settings(\n",
    "    persist_directory=persist_directory,\n",
    "    anonymized_telemetry=False\n",
    ")\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "chroma_client = chromadb.PersistentClient(settings=CHROMA_SETTINGS, path=persist_directory)\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory, \n",
    "    embedding_function=embeddings, \n",
    "    client_settings=CHROMA_SETTINGS, \n",
    "    client=chroma_client\n",
    ")\n",
    "\n",
    "\n",
    "# enforce threshold, don't return on irrelevant search\n",
    "retriever = vectordb.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"k\": top_k,\n",
    "        \"score_threshold\": score_threshold\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load db wrapper and llm\n",
    "\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "db_uri = \"sqlite:///../db/retention-sqlite.db\"\n",
    "model_path = \"../models/ggml-model-gpt4all-falcon-q4_0.bin\"\n",
    "\n",
    "\n",
    "db = SQLDatabase.from_uri(\n",
    "    db_uri,\n",
    "    include_tables=['fact_retention_model'],\n",
    "    sample_rows_in_table_info=2)\n",
    "\n",
    "llm = GPT4All(\n",
    "    model=model_path, \n",
    "    max_tokens=1000, \n",
    "    backend='gptj',\n",
    "    n_batch=8, \n",
    "    callbacks=[StreamingStdOutCallbackHandler()], \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### embeddings prompt template \n",
    "\n",
    "from typing import Any, List\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.prompt_template import BasePromptTemplate\n",
    "from langchain.schema import format_document\n",
    "# from langchain.chains import StuffDocumentsChain\n",
    "import json\n",
    "\n",
    "\n",
    "_specific_question_and_query_file = \"../downloads/retention/question_query.json\"\n",
    "_specific_question_and_query_dict = {}\n",
    "_specific_document_prompt_template = PromptTemplate(input_variables=[\"page_content\"], template=\"{page_content}\")\n",
    "_specific_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\n",
    "\"\"\"Some examples of SQL queries that correspond to questions are listed below:\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "with open(_specific_question_and_query_file, 'r') as file:\n",
    "    _specific_question_and_query_dict = json.load(file)\n",
    "\n",
    "\n",
    "def _get_specific_question_and_query(question: str) -> str:\n",
    "    if question is not None:\n",
    "        try:\n",
    "            return f\"Question: {question}\\nQuery: {_specific_question_and_query_dict[question]}\"\n",
    "        except KeyError as ke:\n",
    "            print(f\"No such key as {question}\")\n",
    "            return question\n",
    "    else:\n",
    "        print(\"Key is none\")\n",
    "        return question\n",
    "\n",
    "\n",
    "def specific_stuff_combine_docs(\n",
    "    question: str,\n",
    "    document_prompt: BasePromptTemplate = _specific_document_prompt_template,\n",
    "    document_separator: str = \"\\n\\n\",\n",
    "    prompt: BasePromptTemplate = _specific_prompt_template,\n",
    "    document_variable_name: str = \"context\",\n",
    "    input_variables: List[str]= [\"context\"],\n",
    "    verbose: bool = False,\n",
    "    **kwargs: Any,\n",
    "    ) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant docs from vectorstore, then\n",
    "    concatenate docs together without going into a LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    if len(docs) == 0:\n",
    "        return \"\"\n",
    "    doc_strings = [_get_specific_question_and_query(format_document(doc, document_prompt)) for doc in docs]\n",
    "    # NOTE: no validation as in StuffDocumentChain:78 get_default_document_variable_name\n",
    "    inputs = {\n",
    "        k: v\n",
    "        for k, v in kwargs.items()\n",
    "        if k in input_variables\n",
    "    }\n",
    "    inputs[document_variable_name] = document_separator.join(doc_strings)\n",
    "    formatted = prompt.format(**inputs)\n",
    "    if verbose:\n",
    "        print(formatted)\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## RunnableSequence\n",
    "First approach, from *create_sql_query_chain*\n",
    "> Be careful while using this approach as it is susceptible to SQL Injection\n",
    "\n",
    "separate invoke and run to migitate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RunnableSequence, no memory\n",
    "\n",
    "import time\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "\n",
    "## NOTE:\n",
    "# This chain automates finding table infos\n",
    "# which we can improve by annotating from an agnet\n",
    "TEMPLATE = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
    "Use the following format:\n",
    "\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Final answer here\"\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "{table_info}.\n",
    "\n",
    "{few_shot_examples}.\n",
    "\n",
    "Question: {input}\"\"\"\n",
    "\n",
    "CUSTOM_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"dialect\", \"top_k\", \"table_info\", \"few_shot_examples\", \"input\"], template=TEMPLATE\n",
    ")\n",
    "\n",
    "_chain = create_sql_query_chain(llm=llm, db=db, prompt=CUSTOM_PROMPT)\n",
    "\n",
    "# Create chain with LangChain Expression Language\n",
    "while True:\n",
    "    question = input(\"\\nEnter a question: \")\n",
    "    if question == \"exit\":\n",
    "        break\n",
    "    if question.strip() == \"\":\n",
    "        continue\n",
    "    \n",
    "    start = time.time()\n",
    "    # NOTE: rlm example\n",
    "    # Refer to https://smith.langchain.com/hub/rlm/text-to-sql\n",
    "    inputs = {\n",
    "        \"table_info\": lambda _: db.get_table_info(),\n",
    "        \"input\": lambda x : x[\"question\"] + \"\\nSQLQuery: \",\n",
    "        \"few_shot_examples\": lambda x: specific_stuff_combine_docs(x[\"question\"]),\n",
    "        \"dialect\":  lambda _: db.dialect,\n",
    "        \"top_k\": lambda _ : 5,\n",
    "    }\n",
    "    # equivalent to _chain, but more flexible\n",
    "    runnableMap = (\n",
    "        inputs\n",
    "        | CUSTOM_PROMPT\n",
    "        | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    sql_response = runnableMap.invoke({\"question\": question})\n",
    "    end = time.time()\n",
    "\n",
    "    # Print the result\n",
    "    print(\"\\n\\n> Question:\")\n",
    "    print(question)\n",
    "    print(f\"\\n> Answer (took {round(end - start, 2)} s.):\")\n",
    "    print(sql_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SQLDataBaseChain with Memory\n",
    "Second approach, basically is my RunnableMap + SQL execution + Memory.\n",
    "> the performance of the SQLDatabaseChain can be enhanced in several ways: </br>\n",
    "* Adding sample rows\n",
    "* Specifying custom table information \n",
    "* Using Query Checker self-correct invalid SQL using parameter use_query_checker=True\n",
    "* Customizing the LLM Prompt include specific instructions or relevant information, using parameter prompt=CUSTOM_PROMPT\n",
    "* Get intermediate steps access the SQL statement as well as the final result using parameter return_intermediate_steps=True \n",
    "* Limit the number of rows a query will return using parameter top_k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Custom prompt for LLMChain in SQLDatabaseChain\n",
    "\n",
    "_sqlite_prompt = \"\"\"You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "_prompt_suffix = \"\"\"Only use the following tables:\n",
    "{table_info}\n",
    "{few_shot_examples}\n",
    "\n",
    "Relevant pieces of previous conversation:\n",
    "{history}\n",
    "(You do not need to use these pieces of information if not relevant)\n",
    "\n",
    "Question: {input}\"\"\"\n",
    "\n",
    "CUSTOM_PROMPT_WITH_FEW_SHOT_EXAMPLES_AND_MEMORY = PromptTemplate(\n",
    "    input_variables=[\"input\", \"table_info\", \"top_k\", \"few_shot_examples\", \"history\"],\n",
    "    template=_sqlite_prompt + _prompt_suffix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fixed in DatabaseChatbot\n",
    "\n",
    "from typing import Any, Dict, Optional, Union\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.schema import BaseMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains.sql_database.prompt import DECIDER_PROMPT, PROMPT, SQL_PROMPTS\n",
    "from langchain.schema.language_model import BaseLanguageModel\n",
    "\n",
    "\n",
    "class LLMChainWithMemory(LLMChain):\n",
    "    def prep_inputs(self, inputs: Dict[str, Any] | Any) -> Dict[str, str]:\n",
    "        if not isinstance(inputs, dict):\n",
    "            _input_keys = set(self.input_keys)\n",
    "            if self.memory is not None:\n",
    "                _input_keys = _input_keys.difference(self.memory.memory_variables)\n",
    "            if len(_input_keys) != 1:\n",
    "                raise ValueError(\n",
    "                    f\"A single string input was passed in, but this chain expects \"\n",
    "                    f\"multiple inputs ({_input_keys}). When a chain expects \"\n",
    "                    f\"multiple inputs, please call it by passing in a dictionary, \"\n",
    "                    \"eg `chain({'foo': 1, 'bar': 2})`\"\n",
    "                )\n",
    "            inputs = {list(_input_keys)[0]: inputs}\n",
    "        \n",
    "        external_context = self.memory.load_memory_variables(inputs) if self.memory is not None else {\"history\" : []}\n",
    "        inputs = dict(inputs, **external_context)\n",
    "        inputs[\"few_shot_examples\"] = specific_stuff_combine_docs(inputs[\"input\"].strip(\"\\nSQLQuery:\"))\n",
    "        self._validate_inputs(inputs)\n",
    "        return inputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SQLDatabaseChain_kwargs = {    \n",
    "    \"return_sql\": False, # Will return sql-command directly without executing it\n",
    "    \"return_intermediate_steps\": False, # Whether or not to return the intermediate steps along with the final answer.\n",
    "    # return_direct: False, # Whether or not to return the result of querying the SQL table directly.\n",
    "    \"use_query_checker\": False, # Whether or not the query checker tool should be used to attempt to fix the initial SQL from the LLM.\n",
    "    # query_checker_prompt: None # The prompt template that should be used by the query checker\n",
    "}\n",
    "\n",
    "memory = ConversationBufferMemory(input_key='input', memory_key=\"history\")\n",
    "chain = SQLDatabaseChain(\n",
    "    llm_chain=LLMChainWithMemory(\n",
    "        llm=llm,     \n",
    "        memory=memory,    \n",
    "        prompt=CUSTOM_PROMPT_WITH_FEW_SHOT_EXAMPLES_AND_MEMORY, # for llm_chain, which is the actual prediction\n",
    "    ),\n",
    "    database=db,\n",
    "    **SQLDatabaseChain_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain({\"query\": \"查询上月末产品类型为投顾类基金保有规模和人数\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(chain.llm_chain.memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain({\"query\": \"这其中招商银行的保有规模是多少\" })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SQLDatabaseSequentialChain\n",
    "Third approch, added benefits on top of second approach. Not flexible enough as Agent.\n",
    "> Determining which tables to use based on the user question </br>\n",
    "> Calling the normal SQL database chain using only relevant tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.sql import SQLDatabaseSequentialChain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
